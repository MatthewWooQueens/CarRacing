{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d3c1dae-d8e4-41d6-b2de-3b69f5bdf61e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gymnasium) (1.26.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gymnasium) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gymnasium) (4.9.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gymnasium) (0.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "802e53d5-b073-49cb-84c7-052a7bdf590f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium[box2d] in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gymnasium[box2d]) (1.26.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gymnasium[box2d]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gymnasium[box2d]) (4.9.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gymnasium[box2d]) (0.0.4)\n",
      "Requirement already satisfied: box2d-py==2.3.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gymnasium[box2d]) (2.3.5)\n",
      "Requirement already satisfied: pygame>=2.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gymnasium[box2d]) (2.5.2)\n",
      "Requirement already satisfied: swig==4.* in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from gymnasium[box2d]) (4.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gymnasium[box2d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd4a36c8-24cd-4490-8f72-bf2334cedd82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24c54efc-f421-4733-84f6-cf76d54e151b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchsummary import summary\n",
    "from torch.distributions.normal import Normal\n",
    "import gymnasium as gym\n",
    "\n",
    "from itertools import count\n",
    "from collections import deque\n",
    "from collections import namedtuple\n",
    "import random\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create environment\n",
    "env = gym.make(\"CarRacing-v2\", domain_randomize=True, continuous=False, render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a955bde-6970-4cfb-8b95-26c6a601918b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "n_actions = env.action_space.n\n",
    "state,_ = env.reset()\n",
    "n_obj = (len(state),len(state[0][0]))\n",
    "class CarAgent():\n",
    "    def __init__(self, batch, learning_rate, epsilon, discount):\n",
    "        self.batch_size = batch\n",
    "        self.lr = learning_rate\n",
    "        self.epsilon = epsilon\n",
    "        self.discount = discount\n",
    "        self.policy_net = carNet(n_obj, n_actions)\n",
    "        self.target_net = carNet(n_obj, n_actions)\n",
    "        self.optimizer = optim.AdamW(self.policy_net.parameters(), lr=self.lr, amsgrad=True)\n",
    "        self.memory = ReplayMemory(10000)\n",
    "        self.steps_done = 0\n",
    "\n",
    "    def select_action(self, state):\n",
    "        sample = random.random()\n",
    "        self.steps_done += 1\n",
    "        if sample > self.epsilon:\n",
    "            with torch.no_grad():\n",
    "                return self.policy_net(state).max(1).indices.view(1,1)\n",
    "        else:\n",
    "            return torch.tensor([[env.action_space.sample()]], device=device)\n",
    "\n",
    "    def optimize_model(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        transitions = self.memory.sample(self.batch_size)\n",
    "\n",
    "        batch = Transition(zip(transitions))\n",
    "\n",
    "        non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), device=device, dtype=torch.bool)\n",
    "\n",
    "        non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "        \n",
    "        state_batch = torch.cat(batch.state)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "        state_action_values = self.policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "        next_state_values = torch.zeros(self.batch_size, device=device)\n",
    "        with torch.no_grad():\n",
    "            next_state_values[non_final_mask] = self.target_net(non_final_next_states).max(1).values\n",
    "        \n",
    "        expected_states_action_values = (next_state_values * self.epsilon)\n",
    "\n",
    "        criterion = nn.SmoothL1Loss()\n",
    "        loss = criterion(state_action_values, expected_states_action_values.unsqueeze(1))\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_value_(self.policy_net.parameters(), 100)\n",
    "        self.optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74a8f926-c0e3-4150-9ba7-9a64c5e2eadf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Comparing current and previous frames\n",
    "class carNet(nn.Module):\n",
    "    def __init__(self, n_observations, n_acts):\n",
    "        super(carNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(3, 32, 3, 1, 1),  nn.ReLU(), nn.MaxPool2d(2, 2), nn.Dropout2d())\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(32, 64, 3, 1, 1),  nn.ReLU(), nn.MaxPool2d(2, 2), nn.Dropout2d())\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(36864, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 128)\n",
    "        self.fc3 = nn.Linear(128,n_acts)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        #print(x.size())\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7fe6f74-d198-4e05-80f8-32ece3d2ea29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ddf9be4-7d90-4123-b535-73d4527457b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(agent):\n",
    "    episode_durations = []\n",
    "    tau = 0.005\n",
    "    num_episodes = 50\n",
    "    if torch.cuda.is_available():\n",
    "        num_episodes = 600\n",
    "        \n",
    "    for i in range(num_episodes):\n",
    "        print(i)\n",
    "        state, info = env.reset()\n",
    "        state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        state = state.permute(0,3,1,2)\n",
    "        for t in count():\n",
    "            print(t)\n",
    "            action = agent.select_action(state)\n",
    "            observation, reward, terminated, truncated, _ = env.step(action.item())\n",
    "            reward = torch.tensor([reward], device=device)\n",
    "            done = terminated or truncated\n",
    "            next_state= None\n",
    "            if not terminated:\n",
    "                next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "                next_state = next_state.permute(0,3,1,2)\n",
    "    \n",
    "            agent.memory.push(state, action, next_state, reward)\n",
    "            state = next_state\n",
    "            agent.optimize_model()\n",
    "            \n",
    "            target_net_state_dict = agent.target_net.state_dict()\n",
    "            policy_net_state_dict = agent.policy_net.state_dict()\n",
    "            \n",
    "            for key in policy_net_state_dict:\n",
    "                target_net_state_dict[key] = policy_net_state_dict[key]*tau + target_net_state_dict[key]*(1-tau)\n",
    "            agent.target_net.load_state_dict(target_net_state_dict)\n",
    "            \n",
    "            if done:\n",
    "                episode_durations.append(t + 1)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6d6072b-4607-4f53-b233-9c1240e6041f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Transition.__new__() missing 3 required positional arguments: 'action', 'next_state', and 'reward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 14\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''state, info = env.reset()\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    print(state)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    s = state.permute(0,3,1,2)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    print(s.size())'''\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m  \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 14\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 3\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m      2\u001b[0m     agent \u001b[38;5;241m=\u001b[39m CarAgent(\u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m0.001\u001b[39m,\u001b[38;5;241m0.1\u001b[39m,\u001b[38;5;241m0.95\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''state, info = env.reset()\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    print(state)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    s = state.permute(0,3,1,2)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    print(s.size())'''\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[32], line 26\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(agent)\u001b[0m\n\u001b[1;32m     24\u001b[0m agent\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mpush(state, action, next_state, reward)\n\u001b[1;32m     25\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[0;32m---> 26\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m target_net_state_dict \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mtarget_net\u001b[38;5;241m.\u001b[39mstate_dict()\n\u001b[1;32m     29\u001b[0m policy_net_state_dict \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mpolicy_net\u001b[38;5;241m.\u001b[39mstate_dict()\n",
      "Cell \u001b[0;32mIn[5], line 32\u001b[0m, in \u001b[0;36mCarAgent.optimize_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     30\u001b[0m transitions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[0;32m---> 32\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[43mTransition\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransitions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m non_final_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m s: s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, batch\u001b[38;5;241m.\u001b[39mnext_state)), device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbool)\n\u001b[1;32m     36\u001b[0m non_final_next_states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mnext_state \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m])\n",
      "\u001b[0;31mTypeError\u001b[0m: Transition.__new__() missing 3 required positional arguments: 'action', 'next_state', and 'reward'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    agent = CarAgent(128,0.001,0.1,0.95)\n",
    "    train(agent)\n",
    "    '''state, info = env.reset()\n",
    "    print(state)\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    print(state)\n",
    "    p = carNet(0,5)\n",
    "    summary(p,(3,96,96))\n",
    "    s = state.permute(0,3,1,2)\n",
    "    print(s.size())'''\n",
    "    \n",
    "if __name__  == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b2328-4062-413f-9400-d7dadb334e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
